#!/usr/bin/env python3
"""
ZephyrUI æ–‡æ¡£è´¨é‡æ£€æŸ¥å·¥å…·
æ£€æŸ¥æ–‡æ¡£è´¨é‡ã€æ ¼å¼è§„èŒƒå’Œå†…å®¹å®Œæ•´æ€§
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime

@dataclass
class DocIssue:
    """æ–‡æ¡£é—®é¢˜"""
    file_path: str
    line_number: int
    issue_type: str
    severity: str
    message: str
    suggestion: str

@dataclass
class DocQualityScore:
    """æ–‡æ¡£è´¨é‡è¯„åˆ†"""
    file_path: str
    total_score: float
    content_score: float
    format_score: float
    structure_score: float
    issues: List[DocIssue]

class DocsQualityChecker:
    def __init__(self, docs_dir: str = "doc"):
        self.docs_dir = Path(docs_dir)
        self.issues: List[DocIssue] = []
        self.scores: List[DocQualityScore] = []
        self.quality_rules = self.load_quality_rules()
        
    def load_quality_rules(self) -> Dict:
        """åŠ è½½è´¨é‡æ£€æŸ¥è§„åˆ™"""
        return {
            'content': {
                'required_sections': [
                    '## ğŸ¯ ç»„ä»¶æ¦‚è¿°',
                    '## ğŸš€ åŸºç¡€ç”¨æ³•',
                    '## ğŸ¨ æ ·å¼å®šåˆ¶',
                    '## ğŸ›ï¸ API å‚è€ƒ',
                    '## ğŸ† æœ€ä½³å®è·µ'
                ],
                'min_code_examples': 3,
                'min_description_length': 100,
                'max_description_length': 2000,
                'required_properties': ['title', 'description', 'version']
            },
            'format': {
                'max_line_length': 120,
                'required_frontmatter': True,
                'code_block_language': True,
                'heading_blank_lines': True,
                'table_format': True
            },
            'structure': {
                'max_file_size': 100 * 1024,  # 100KB
                'required_headings': 3,
                'min_sections': 5,
                'logical_order': True
            }
        }
    
    def find_markdown_files(self) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰Markdownæ–‡ä»¶"""
        return list(self.docs_dir.rglob("*.md"))
    
    def check_file_quality(self, file_path: Path) -> DocQualityScore:
        """æ£€æŸ¥å•ä¸ªæ–‡ä»¶è´¨é‡"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
        except Exception as e:
            return DocQualityScore(
                file_path=str(file_path),
                total_score=0,
                content_score=0,
                format_score=0,
                structure_score=0,
                issues=[DocIssue(
                    file_path=str(file_path),
                    line_number=0,
                    issue_type='file_read_error',
                    severity='critical',
                    message=f'æ— æ³•è¯»å–æ–‡ä»¶: {e}',
                    suggestion='æ£€æŸ¥æ–‡ä»¶æƒé™å’Œç¼–ç '
                )]
            )
        
        # æ£€æŸ¥å†…å®¹è´¨é‡
        content_score, content_issues = self.check_content_quality(file_path, content, lines)
        issues.extend(content_issues)
        
        # æ£€æŸ¥æ ¼å¼è´¨é‡
        format_score, format_issues = self.check_format_quality(file_path, content, lines)
        issues.extend(format_issues)
        
        # æ£€æŸ¥ç»“æ„è´¨é‡
        structure_score, structure_issues = self.check_structure_quality(file_path, content, lines)
        issues.extend(structure_issues)
        
        # è®¡ç®—æ€»åˆ†
        total_score = (content_score * 0.4 + format_score * 0.3 + structure_score * 0.3)
        
        return DocQualityScore(
            file_path=str(file_path),
            total_score=total_score,
            content_score=content_score,
            format_score=format_score,
            structure_score=structure_score,
            issues=issues
        )
    
    def check_content_quality(self, file_path: Path, content: str, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥å†…å®¹è´¨é‡"""
        issues = []
        score = 100.0
        
        # æ£€æŸ¥frontmatter
        frontmatter_score, frontmatter_issues = self.check_frontmatter(file_path, content, lines)
        score += frontmatter_score * 0.2
        issues.extend(frontmatter_issues)
        
        # æ£€æŸ¥å¿…éœ€ç« èŠ‚
        sections_score, sections_issues = self.check_required_sections(file_path, content, lines)
        score += sections_score * 0.3
        issues.extend(sections_issues)
        
        # æ£€æŸ¥ä»£ç ç¤ºä¾‹
        code_score, code_issues = self.check_code_examples(file_path, content, lines)
        score += code_score * 0.3
        issues.extend(code_issues)
        
        # æ£€æŸ¥æè¿°è´¨é‡
        desc_score, desc_issues = self.check_description_quality(file_path, content, lines)
        score += desc_score * 0.2
        issues.extend(desc_issues)
        
        return min(score, 100), issues
    
    def check_frontmatter(self, file_path: Path, content: str, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥frontmatter"""
        issues = []
        score = 100.0
        
        if not content.startswith('---'):
            issues.append(DocIssue(
                file_path=str(file_path),
                line_number=1,
                issue_type='missing_frontmatter',
                severity='major',
                message='æ–‡æ¡£ç¼ºå°‘frontmatter',
                suggestion='åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ frontmatterï¼ŒåŒ…å«titleã€descriptionã€versionç­‰ä¿¡æ¯'
            ))
            score -= 50
        else:
            # æ£€æŸ¥å¿…éœ€å±æ€§
            frontmatter_end = content.find('---', 3)
            if frontmatter_end == -1:
                issues.append(DocIssue(
                    file_path=str(file_path),
                    line_number=1,
                    issue_type='invalid_frontmatter',
                    severity='major',
                    message='Frontmatteræ ¼å¼é”™è¯¯',
                    suggestion='ç¡®ä¿frontmatterä»¥---å¼€å§‹å’Œç»“æŸ'
                ))
                score -= 30
            else:
                frontmatter_content = content[3:frontmatter_end]
                
                required_props = self.quality_rules['content']['required_properties']
                for prop in required_props:
                    if prop not in frontmatter_content:
                        issues.append(DocIssue(
                            file_path=str(file_path),
                            line_number=1,
                            issue_type=f'missing_frontmatter_{prop}',
                            severity='minor',
                            message=f'Frontmatterç¼ºå°‘{prop}å±æ€§',
                            suggestion=f'åœ¨frontmatterä¸­æ·»åŠ {prop}: å€¼'
                        ))
                        score -= 10
        
        return score, issues
    
    def check_required_sections(self, file_path: Path, content: str, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥å¿…éœ€ç« èŠ‚"""
        issues = []
        score = 100.0
        
        required_sections = self.quality_rules['content']['required_sections']
        missing_sections = []
        
        for section in required_sections:
            if section not in content:
                missing_sections.append(section)
        
        if missing_sections:
            issues.append(DocIssue(
                file_path=str(file_path),
                line_number=1,
                issue_type='missing_sections',
                severity='major',
                message=f'ç¼ºå°‘å¿…éœ€ç« èŠ‚: {", ".join(missing_sections)}',
                suggestion=f'æ·»åŠ ç¼ºå¤±çš„ç« èŠ‚: {", ".join(missing_sections)}'
            ))
            score -= len(missing_sections) * 15
        
        return score, issues
    
    def check_code_examples(self, file_path: Path, content: str, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥ä»£ç ç¤ºä¾‹"""
        issues = []
        score = 100.0
        
        # ç»Ÿè®¡ä»£ç å—æ•°é‡
        code_blocks = re.findall(r'```dart\n.*?\n```', content, re.DOTALL)
        code_count = len(code_blocks)
        
        min_examples = self.quality_rules['content']['min_code_examples']
        if code_count < min_examples:
            issues.append(DocIssue(
                file_path=str(file_path),
                line_number=1,
                issue_type='insufficient_code_examples',
                severity='minor',
                message=f'ä»£ç ç¤ºä¾‹æ•°é‡ä¸è¶³: {code_count} < {min_examples}',
                suggestion=f'æ·»åŠ è‡³å°‘{min_examples}ä¸ªä»£ç ç¤ºä¾‹'
            ))
            score -= (min_examples - code_count) * 10
        
        # æ£€æŸ¥ä»£ç å—è¯­è¨€æ ‡è¯†
        untagged_blocks = re.findall(r'```\n(.*?)\n```', content, re.DOTALL)
        if untagged_blocks:
            issues.append(DocIssue(
                file_path=str(file_path),
                line_number=1,
                issue_type='untagged_code_blocks',
                severity='minor',
                message=f'å‘ç°{len(untagged_blocks)}ä¸ªæœªæ ‡è¯†è¯­è¨€çš„ä»£ç å—',
                suggestion='ä¸ºæ‰€æœ‰ä»£ç å—æ·»åŠ è¯­è¨€æ ‡è¯†ï¼Œå¦‚```dart'
            ))
            score -= len(untagged_blocks) * 5
        
        return score, issues
    
    def check_description_quality(self, file_path: Path, content: str, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥æè¿°è´¨é‡"""
        issues = []
        score = 100.0
        
        # æå–ä¸»è¦æè¿°ï¼ˆfrontmatteråçš„ç¬¬ä¸€æ®µæ–‡å­—ï¼‰
        description_match = re.search(r'---\n.*?\n---\n\n(.+?)(?=\n\n#|\n##)', content, re.DOTALL)
        if description_match:
            description = description_match.group(1)
            desc_length = len(description)
            
            min_length = self.quality_rules['content']['min_description_length']
            max_length = self.quality_rules['content']['max_description_length']
            
            if desc_length < min_length:
                issues.append(DocIssue(
                    file_path=str(file_path),
                    line_number=1,
                    issue_type='short_description',
                    severity='minor',
                    message=f'æè¿°è¿‡çŸ­: {desc_length} < {min_length}',
                    suggestion=f'æ‰©å±•æè¿°è‡³å°‘åˆ°{min_length}å­—ç¬¦'
                ))
                score -= 20
            
            if desc_length > max_length:
                issues.append(DocIssue(
                    file_path=str(file_path),
                    line_number=1,
                    issue_type='long_description',
                    severity='minor',
                    message=f'æè¿°è¿‡é•¿: {desc_length} > {max_length}',
                    suggestion=f'ç²¾ç®€æè¿°åˆ°{max_length}å­—ç¬¦ä»¥å†…'
                ))
                score -= 10
        else:
            issues.append(DocIssue(
                file_path=str(file_path),
                line_number=1,
                issue_type='missing_description',
                severity='major',
                message='ç¼ºå°‘æ–‡æ¡£æè¿°',
                suggestion='åœ¨frontmatteråæ·»åŠ ç»„ä»¶æè¿°'
            ))
            score -= 50
        
        return score, issues
    
    def check_format_quality(self, file_path: Path, content: str, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥æ ¼å¼è´¨é‡"""
        issues = []
        score = 100.0
        
        # æ£€æŸ¥è¡Œé•¿åº¦
        line_length_score, line_length_issues = self.check_line_length(file_path, lines)
        score += line_length_score * 0.3
        issues.extend(line_length_issues)
        
        # æ£€æŸ¥æ ‡é¢˜æ ¼å¼
        heading_score, heading_issues = self.check_heading_format(file_path, lines)
        score += heading_score * 0.3
        issues.extend(heading_issues)
        
        # æ£€æŸ¥è¡¨æ ¼æ ¼å¼
        table_score, table_issues = self.check_table_format(file_path, lines)
        score += table_score * 0.2
        issues.extend(table_issues)
        
        # æ£€æŸ¥é“¾æ¥æ ¼å¼
        link_score, link_issues = self.check_link_format(file_path, lines)
        score += link_score * 0.2
        issues.extend(link_issues)
        
        return min(score, 100), issues
    
    def check_line_length(self, file_path: Path, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥è¡Œé•¿åº¦"""
        issues = []
        score = 100.0
        
        max_length = self.quality_rules['format']['max_line_length']
        long_lines = []
        
        for i, line in enumerate(lines, 1):
            if len(line) > max_length and not line.startswith('http'):
                long_lines.append((i, len(line)))
        
        if long_lines:
            issues.append(DocIssue(
                file_path=str(file_path),
                line_number=long_lines[0][0],
                issue_type='long_lines',
                severity='minor',
                message=f'å‘ç°{len(long_lines)}è¡Œè¿‡é•¿çš„æ–‡æœ¬',
                suggestion=f'å°†é•¿è¡Œæ‹†åˆ†ä¸ºå¤šè¡Œï¼Œæ¯è¡Œä¸è¶…è¿‡{max_length}å­—ç¬¦'
            ))
            score -= len(long_lines) * 2
        
        return score, issues
    
    def check_heading_format(self, file_path: Path, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥æ ‡é¢˜æ ¼å¼"""
        issues = []
        score = 100.0
        
        for i, line in enumerate(lines, 1):
            if line.startswith('#'):
                # æ£€æŸ¥æ ‡é¢˜å‰åæ˜¯å¦æœ‰ç©ºè¡Œ
                has_blank_before = i == 1 or lines[i-2].strip() == ''
                has_blank_after = i == len(lines) or lines[i].strip() == ''
                
                if self.quality_rules['format']['heading_blank_lines']:
                    if not has_blank_before:
                        issues.append(DocIssue(
                            file_path=str(file_path),
                            line_number=i,
                            issue_type='heading_format',
                            severity='minor',
                            message='æ ‡é¢˜å‰ç¼ºå°‘ç©ºè¡Œ',
                            suggestion='åœ¨æ ‡é¢˜å‰æ·»åŠ ç©ºè¡Œ'
                        ))
                        score -= 5
                    
                    if not has_blank_after:
                        issues.append(DocIssue(
                            file_path=str(file_path),
                            line_number=i,
                            issue_type='heading_format',
                            severity='minor',
                            message='æ ‡é¢˜åç¼ºå°‘ç©ºè¡Œ',
                            suggestion='åœ¨æ ‡é¢˜åæ·»åŠ ç©ºè¡Œ'
                        ))
                        score -= 5
        
        return score, issues
    
    def check_table_format(self, file_path: Path, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥è¡¨æ ¼æ ¼å¼"""
        issues = []
        score = 100.0
        
        for i, line in enumerate(lines, 1):
            if '|' in line and line.strip().startswith('|'):
                # æ£€æŸ¥è¡¨æ ¼æ ¼å¼
                cells = [cell.strip() for cell in line.split('|')]
                if len(cells) < 3:  # è‡³å°‘éœ€è¦ | å†…å®¹ | 
                    issues.append(DocIssue(
                        file_path=str(file_path),
                        line_number=i,
                        issue_type='table_format',
                        severity='minor',
                        message='è¡¨æ ¼æ ¼å¼ä¸æ­£ç¡®',
                        suggestion='ç¡®ä¿è¡¨æ ¼è¡Œæ ¼å¼ä¸º | å•å…ƒæ ¼1 | å•å…ƒæ ¼2 |'
                    ))
                    score -= 10
        
        return score, issues
    
    def check_link_format(self, file_path: Path, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥é“¾æ¥æ ¼å¼"""
        issues = []
        score = 100.0
        
        for i, line in enumerate(lines, 1):
            # æ£€æŸ¥Markdowné“¾æ¥æ ¼å¼
            markdown_links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', line)
            for text, url in markdown_links:
                if not url.startswith('http') and not url.startswith('#'):
                    # æ£€æŸ¥å†…éƒ¨é“¾æ¥
                    if not url.endswith('.md'):
                        issues.append(DocIssue(
                            file_path=str(file_path),
                            line_number=i,
                            issue_type='link_format',
                            severity='minor',
                            message=f'å†…éƒ¨é“¾æ¥æ ¼å¼ä¸æ­£ç¡®: {url}',
                            suggestion='ç¡®ä¿å†…éƒ¨é“¾æ¥æŒ‡å‘.mdæ–‡ä»¶'
                        ))
                        score -= 5
        
        return score, issues
    
    def check_structure_quality(self, file_path: Path, content: str, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥ç»“æ„è´¨é‡"""
        issues = []
        score = 100.0
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = len(content.encode('utf-8'))
        max_size = self.quality_rules['structure']['max_file_size']
        
        if file_size > max_size:
            issues.append(DocIssue(
                file_path=str(file_path),
                line_number=1,
                issue_type='large_file',
                severity='minor',
                message=f'æ–‡ä»¶è¿‡å¤§: {file_size} > {max_size}',
                suggestion='è€ƒè™‘æ‹†åˆ†å¤§æ–‡ä»¶æˆ–ç²¾ç®€å†…å®¹'
            ))
            score -= 20
        
        # æ£€æŸ¥ç« èŠ‚æ•°é‡
        sections = re.findall(r'^## ', content, re.MULTILINE)
        min_sections = self.quality_rules['structure']['min_sections']
        
        if len(sections) < min_sections:
            issues.append(DocIssue(
                file_path=str(file_path),
                line_number=1,
                issue_type='few_sections',
                severity='minor',
                message=f'ç« èŠ‚æ•°é‡ä¸è¶³: {len(sections)} < {min_sections}',
                suggestion=f'æ·»åŠ æ›´å¤šç« èŠ‚ï¼Œè‡³å°‘{min_sections}ä¸ª'
            ))
            score -= 15
        
        # æ£€æŸ¥é€»è¾‘é¡ºåº
        order_score, order_issues = self.check_logical_order(file_path, content, lines)
        score += order_score * 0.3
        issues.extend(order_issues)
        
        return min(score, 100), issues
    
    def check_logical_order(self, file_path: Path, content: str, lines: List[str]) -> Tuple[float, List[DocIssue]]:
        """æ£€æŸ¥é€»è¾‘é¡ºåº"""
        issues = []
        score = 100.0
        
        # å®šä¹‰æœŸæœ›çš„ç« èŠ‚é¡ºåº
        expected_order = [
            '## ğŸ¯ ç»„ä»¶æ¦‚è¿°',
            '## ğŸš€ åŸºç¡€ç”¨æ³•',
            '## ğŸ¨ æ ·å¼å®šåˆ¶',
            '## ğŸ›ï¸ API å‚è€ƒ',
            '## ğŸ† æœ€ä½³å®è·µ',
            '## ğŸ”„ ç›¸å…³ç»„ä»¶',
            '## ğŸ“ æ›´æ–°æ—¥å¿—'
        ]
        
        # æŸ¥æ‰¾å®é™…ç« èŠ‚
        actual_sections = []
        for line in lines:
            if line.startswith('## '):
                actual_sections.append(line)
        
        # æ£€æŸ¥é¡ºåº
        for i, expected in enumerate(expected_order):
            if expected in actual_sections:
                expected_index = actual_sections.index(expected)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´é‡è¦çš„ç« èŠ‚åœ¨åé¢
                for j in range(i + 1, len(expected_order)):
                    if expected_order[j] in actual_sections:
                        later_index = actual_sections.index(expected_order[j])
                        if later_index < expected_index:
                            issues.append(DocIssue(
                                file_path=str(file_path),
                                line_number=lines.index(expected) + 1,
                                issue_type='logical_order',
                                severity='minor',
                                message=f'ç« èŠ‚é¡ºåºä¸åˆç†: {expected} åº”è¯¥åœ¨ {expected_order[j]} ä¹‹å',
                                suggestion='è°ƒæ•´ç« èŠ‚é¡ºåºï¼Œç¬¦åˆé€»è¾‘æµç¨‹'
                            ))
                            score -= 10
                            break
        
        return score, issues
    
    def check_all_files(self):
        """æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶è´¨é‡"""
        markdown_files = self.find_markdown_files()
        
        for file_path in markdown_files:
            print(f"æ£€æŸ¥æ–‡ä»¶: {file_path}")
            score = self.check_file_quality(file_path)
            self.scores.append(score)
            self.issues.extend(score.issues)
    
    def generate_quality_report(self):
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        # ç»Ÿè®¡ä¿¡æ¯
        total_files = len(self.scores)
        files_with_issues = len([s for s in self.scores if s.issues])
        total_issues = len(self.issues)
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
        severity_counts = {}
        for issue in self.issues:
            severity = issue.severity
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        # æŒ‰é—®é¢˜ç±»å‹ç»Ÿè®¡
        type_counts = {}
        for issue in self.issues:
            issue_type = issue.issue_type
            type_counts[issue_type] = type_counts.get(issue_type, 0) + 1
        
        # è®¡ç®—å¹³å‡åˆ†
        avg_score = sum(s.total_score for s in self.scores) / len(self.scores) if self.scores else 0
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'summary': {
                'total_files': total_files,
                'files_with_issues': files_with_issues,
                'total_issues': total_issues,
                'average_score': avg_score,
                'quality_grade': self.get_quality_grade(avg_score)
            },
            'severity_breakdown': severity_counts,
            'issue_type_breakdown': type_counts,
            'file_scores': [
                {
                    'file_path': score.file_path,
                    'total_score': score.total_score,
                    'content_score': score.content_score,
                    'format_score': score.format_score,
                    'structure_score': score.structure_score,
                    'issue_count': len(score.issues)
                }
                for score in self.scores
            ],
            'issues': [
                {
                    'file_path': issue.file_path,
                    'line_number': issue.line_number,
                    'issue_type': issue.issue_type,
                    'severity': issue.severity,
                    'message': issue.message,
                    'suggestion': issue.suggestion
                }
                for issue in self.issues
            ],
            'recommendations': self.generate_recommendations()
        }
        
        # ä¿å­˜æŠ¥å‘Š
        with open('docs-quality-report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆäººç±»å¯è¯»çš„æŠ¥å‘Š
        self.generate_human_readable_report(report)
        
        print(f"è´¨é‡æ£€æŸ¥å®Œæˆ!")
        print(f"æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"æœ‰é—®é¢˜çš„æ–‡ä»¶: {files_with_issues}")
        print(f"æ€»é—®é¢˜æ•°: {total_issues}")
        print(f"å¹³å‡è´¨é‡åˆ†: {avg_score:.1f}")
        print(f"è´¨é‡ç­‰çº§: {self.get_quality_grade(avg_score)}")
        print("è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ° docs-quality-report.json")
    
    def get_quality_grade(self, score: float) -> str:
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 90:
            return "ä¼˜ç§€"
        elif score >= 80:
            return "è‰¯å¥½"
        elif score >= 70:
            return "ä¸­ç­‰"
        elif score >= 60:
            return "åŠæ ¼"
        else:
            return "ä¸åŠæ ¼"
    
    def generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # åŸºäºé—®é¢˜ç±»å‹çš„å»ºè®®
        type_counts = {}
        for issue in self.issues:
            issue_type = issue.issue_type
            type_counts[issue_type] = type_counts.get(issue_type, 0) + 1
        
        if 'missing_frontmatter' in type_counts:
            recommendations.append("ä¸ºæ‰€æœ‰æ–‡æ¡£æ·»åŠ frontmatterï¼ŒåŒ…å«titleã€descriptionã€versionç­‰ä¿¡æ¯")
        
        if 'missing_sections' in type_counts:
            recommendations.append("ç¡®ä¿æ‰€æœ‰ç»„ä»¶æ–‡æ¡£éƒ½åŒ…å«å¿…éœ€çš„ç« èŠ‚ï¼šç»„ä»¶æ¦‚è¿°ã€åŸºç¡€ç”¨æ³•ã€æ ·å¼å®šåˆ¶ã€APIå‚è€ƒã€æœ€ä½³å®è·µ")
        
        if 'insufficient_code_examples' in type_counts:
            recommendations.append("ä¸ºæ¯ä¸ªç»„ä»¶æ·»åŠ è‡³å°‘3ä¸ªä»£ç ç¤ºä¾‹ï¼Œæ¶µç›–ä¸åŒä½¿ç”¨åœºæ™¯")
        
        if 'long_lines' in type_counts:
            recommendations.append("å°†è¿‡é•¿çš„è¡Œæ‹†åˆ†ä¸ºå¤šè¡Œï¼Œæ¯è¡Œä¸è¶…è¿‡120ä¸ªå­—ç¬¦")
        
        if 'heading_format' in type_counts:
            recommendations.append("ç¡®ä¿æ ‡é¢˜å‰åæœ‰ç©ºè¡Œï¼Œä¿æŒæ ¼å¼ç»Ÿä¸€")
        
        if 'link_format' in type_counts:
            recommendations.append("ç»Ÿä¸€é“¾æ¥æ ¼å¼ï¼Œç¡®ä¿å†…éƒ¨é“¾æ¥æŒ‡å‘æ­£ç¡®çš„.mdæ–‡ä»¶")
        
        return recommendations
    
    def generate_human_readable_report(self, report: Dict):
        """ç”Ÿæˆäººç±»å¯è¯»çš„æŠ¥å‘Š"""
        report_content = f"""# ZephyrUI æ–‡æ¡£è´¨é‡æ£€æŸ¥æŠ¥å‘Š

**æ£€æŸ¥æ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**æ£€æŸ¥æ–‡ä»¶æ•°**: {report['summary']['total_files']}  
**æœ‰é—®é¢˜çš„æ–‡ä»¶**: {report['summary']['files_with_issues']}  
**æ€»é—®é¢˜æ•°**: {report['summary']['total_issues']}  
**å¹³å‡è´¨é‡åˆ†**: {report['summary']['average_score']:.1f}  
**è´¨é‡ç­‰çº§**: {report['summary']['quality_grade']}

## ğŸ“Š è´¨é‡ç»Ÿè®¡

### é—®é¢˜ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
"""
        
        for severity, count in report['severity_breakdown'].items():
            report_content += f"- **{severity}**: {count} ä¸ªé—®é¢˜\n"
        
        report_content += "\n### é—®é¢˜ç±»å‹åˆ†å¸ƒ\n"
        
        for issue_type, count in report['issue_type_breakdown'].items():
            report_content += f"- **{issue_type}**: {count} ä¸ªé—®é¢˜\n"
        
        report_content += "\n## ğŸ“ˆ æ–‡ä»¶è´¨é‡è¯„åˆ†\n\n"
        
        for file_score in report['file_scores']:
            grade = self.get_quality_grade(file_score['total_score'])
            report_content += f"### {file_score['file_path']}\n"
            report_content += f"- **æ€»åˆ†**: {file_score['total_score']:.1f} ({grade})\n"
            report_content += f"- **å†…å®¹åˆ†**: {file_score['content_score']:.1f}\n"
            report_content += f"- **æ ¼å¼åˆ†**: {file_score['format_score']:.1f}\n"
            report_content += f"- **ç»“æ„åˆ†**: {file_score['structure_score']:.1f}\n"
            report_content += f"- **é—®é¢˜æ•°**: {file_score['issue_count']}\n\n"
        
        report_content += "## ğŸ”§ æ”¹è¿›å»ºè®®\n\n"
        
        for i, recommendation in enumerate(report['recommendations'], 1):
            report_content += f"{i}. {recommendation}\n"
        
        report_content += "\n## ğŸ“‹ è¯¦ç»†é—®é¢˜åˆ—è¡¨\n\n"
        
        for issue in report['issues']:
            report_content += f"### {issue['file_path']}:{issue['line_number']}\n"
            report_content += f"**ç±»å‹**: {issue['issue_type']}  \n"
            report_content += f"**ä¸¥é‡ç¨‹åº¦**: {issue['severity']}  \n"
            report_content += f"**é—®é¢˜**: {issue['message']}  \n"
            report_content += f"**å»ºè®®**: {issue['suggestion']}\n\n"
        
        # ä¿å­˜äººç±»å¯è¯»æŠ¥å‘Š
        with open('docs-quality-report.md', 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print("äººç±»å¯è¯»æŠ¥å‘Šå·²ä¿å­˜åˆ° docs-quality-report.md")

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹æ£€æŸ¥ZephyrUIæ–‡æ¡£è´¨é‡...")
    
    checker = DocsQualityChecker()
    
    # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶
    checker.check_all_files()
    
    # ç”Ÿæˆè´¨é‡æŠ¥å‘Š
    checker.generate_quality_report()
    
    print("æ–‡æ¡£è´¨é‡æ£€æŸ¥å®Œæˆ!")

if __name__ == "__main__":
    main()